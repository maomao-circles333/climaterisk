{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1742fa9",
   "metadata": {},
   "source": [
    "# The Great Green Wall in Senegal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96a9058",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "[The Great Green Wall](https://en.wikipedia.org/wiki/Great_Green_Wall_(Africa)) is an effort to combat the spread of the Sahara desert by growing vegetation in a systematic and scientific manner. The [OPERA DIST-ALERT data product](https://lpdaac.usgs.gov/documents/1766/OPERA_DIST_HLS_Product_Specification_V1.pdf) can also be used to identify changes in the growth of vegetation (implying natural or, in this case, anthropogenic causes).\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Sahara_satellite_hires.jpg/800px-Sahara_satellite_hires.jpg\"></img>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcf4407",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d51cc",
   "metadata": {},
   "source": [
    "## Outline of steps for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d11fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "+ Identifying search parameters (AOI, time-window, endpoint, etc.)\n",
    "+ Obtaining search results in a `DataFrame`\n",
    "+ Exploring & refining search results\n",
    "+ Data-wrangling to produce relevant output\n",
    "\n",
    "In this case, we'll assemble a DataFrame to summarize search results, trim down the results to a manageable size, and make an interactive slider to examine the data retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f019992",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db638bc7",
   "metadata": {},
   "source": [
    "### Preliminary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785af0d6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c31decd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63bcd1d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from osgeo import gdal\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca745b77",
   "metadata": {},
   "source": [
    "### Convenient utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0468eb86",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to make a rectangle with given center of width dx & height dy\n",
    "def make_bbox(pt,dx,dy):\n",
    "    '''Returns bounding-box represented as tuple (x_lo, y_lo, x_hi, y_hi)\n",
    "    given inputs pt=(x, y), width & height dx & dy respectively,\n",
    "    where x_lo = x-dx/2, x_hi=x+dx/2, y_lo = y-dy/2, y_hi = y+dy/2.\n",
    "    '''\n",
    "    return tuple(coord+sgn*delta for sgn in (-1,+1) for coord,delta in zip(pt, (dx/2,dy/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3d737",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to plot an AOI or bounding-box\n",
    "def plot_bbox(bbox):\n",
    "    '''Given bounding-box, returns GeoViews plot of Rectangle & Point at center\n",
    "    + bbox: bounding-box specified as (lon_min, lat_min, lon_max, lat_max)\n",
    "    Assume longitude-latitude coordinates.\n",
    "    '''\n",
    "    # These plot options are fixed but can be over-ridden\n",
    "    point_opts = opts.Points(size=12, alpha=0.25, color='blue')\n",
    "    rect_opts = opts.Rectangles(line_width=0, alpha=0.1, color='red')\n",
    "    lon_lat = (0.5*sum(bbox[::2]), 0.5*sum(bbox[1::2]))\n",
    "    return (gv.Points([lon_lat]) * gv.Rectangles([bbox])).opts(point_opts, rect_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111fd577",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to extract search results into a Pandas DataFrame\n",
    "def search_to_dataframe(search_results):\n",
    "    '''Constructs Pandas DataFrame from PySTAC Earthdata search results.\n",
    "    DataFrame columns are determined from search item properties and assets.'''\n",
    "    # Extract granules into a list of searh items\n",
    "    granules = list(search_results.items())\n",
    "    assert granules, \"Error: empty list of search results\"\n",
    "    # Determine column labels from unique properties from all granules\n",
    "    properties = sorted(list({prop for g in granules for prop in g.properties.keys()}))\n",
    "    # Assemble blocks of rows from each granule\n",
    "    blocks = []\n",
    "    for g in granules:\n",
    "        # Leftmost columns determined from properties\n",
    "        left = pd.Series(index=properties)\n",
    "        for p in properties:\n",
    "            left.loc[p] = g.properties.get(p, None)\n",
    "        tile_id = g.id.split('_')[3]\n",
    "        left.loc['tile_id'] = tile_id\n",
    "        left = pd.DataFrame(left).T\n",
    "        right = []\n",
    "        for a in sorted(g.assets.keys()):\n",
    "            href = g.assets[a].href\n",
    "            # Ignore hrefs using Amazon s3 (not currently working with rasterio)\n",
    "            if href.startswith('s3://'):\n",
    "                continue\n",
    "            right.append(pd.DataFrame(data=dict(asset=a, href=href), index=[0]))\n",
    "        # Use outer join to create block from left row and right block\n",
    "        blocks.append(left.join(pd.concat(right, axis=0, ignore_index=True), how='outer'))\n",
    "    # Stack blocks into final dataframe, forward-filling as needed\n",
    "    df = pd.concat(blocks, axis=0, ignore_index=True).ffill(axis=0)\n",
    "    assert len(df), \"Empty DataFrame\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa98dbf2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to process DataFrame of search results & return DataArray of stacked raster images\n",
    "def stack_time_slices(granule_dataframe):\n",
    "    '''This function returns a three-dimensional Xarray DataArray comprising time slices read from GeoTIFF files.\n",
    "    - Input: a DataFrame of granules (i.e., a DataFrame with a DateTimeIndex and a column 'href' of URIs).\n",
    "    - Output: a stacked DataArray with dimensions ('time', 'longitude', 'latitude')\n",
    "    - GeoTIFF data are assumed to have been acquired over the same MGRS tile (NOT verified within).\n",
    "    - Note CRS explicitly embedded into DataArray stack as extracted from GeoTIFF file.\n",
    "    - DataArray is constructed using np.datetime64 time axis to simplify visualization.'''\n",
    "    slices, timestamps = list(), list()\n",
    "    for timestamp_, row_ in granule_dataframe.iterrows():\n",
    "        da_ = rio.open_rasterio(row_['href'])\n",
    "        # Preserve coordinate arrays from last GeoTIFF file parsed\n",
    "        x, y = da_.coords['x'].values, da_.coords['y'].values\n",
    "        slices.append(da_.values)\n",
    "        timestamps.append(np.datetime64(timestamp_,'s'))\n",
    "    # Construct time axis from accumulated timestamps\n",
    "    time = np.array(timestamps)\n",
    "    # Construct DataArray stack from accumulated slices & coordinates\n",
    "    slices = np.concatenate(slices, axis=0)\n",
    "    coords = dict(time=time, longitude=x, latitude=y)\n",
    "    stack = xr.DataArray(data=slices, coords=coords, dims=['time', 'latitude', 'longitude'])\n",
    "    # Preserve coordinate reference system (CRS) in DataArray stack\n",
    "    crs = da_.rio.crs\n",
    "    stack.rio.write_crs(crs, inplace=True)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abc166",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "These functions could be placed in module files for more developed research projects. For learning purposes, they are embedded within this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a89099",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9f7c1c",
   "metadata": {},
   "source": [
    "## Obtaining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef0ea6b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The Great Green Wall spans the African continent; we'll choose an area-of-interest centered at the geographic coordinates $(-16.0913^{\\circ}, 16.528^{\\circ})$ in Senegal. We'll look at as much data as is available from January 2022 until the end of March 2024. We'll use the identifiers `AOI` and `DATE_RANGE` to eventually be used in a PySTAC search query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c957162a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AOI = make_bbox((-16.0913, 16.528), 0.1, 0.1)\n",
    "DATE_RANGE = \"2022-01-01/2024-03-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb953f40",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The plot generated below illustrates the AOI; the Bokeh Zoom tools are useful to examine the box on several length scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4925fbe8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Optionally plot the AOI\n",
    "basemap = gv.tile_sources.OSM(padding=0.1, alpha=0.25)\n",
    "plot_bbox(AOI) * basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f0d245",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "search_params = dict(bbox=AOI, datetime=DATE_RANGE)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a312d09",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "To execute the search, we define the endpoint URI and instantiate a `Client` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06073c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "PROVIDER = 'LPCLOUD'\n",
    "COLLECTIONS = [\"OPERA_L3_DIST-ALERT-HLS_V1_1\"]\n",
    "search_params.update(collections=COLLECTIONS)\n",
    "print(search_params)\n",
    "\n",
    "catalog = Client.open(f'{ENDPOINT}/{PROVIDER}/')\n",
    "search_results = catalog.search(**search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b2d2f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The search itself is quite fast and yields a few thousand results that can be more easily examined in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7609ef48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = search_to_dataframe(search_results)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b92748a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We clean the `DataFrame` `df` in typical ways that make sense:\n",
    "\n",
    "+ renaming the `eo:cloud_cover` column as `cloud_cover`;\n",
    "+ dropping extraneous `datetime` columns;\n",
    "+ casting columns to sensible datatypes;\n",
    "+ casting the `datetime` column as `DatetimeIndex`; and\n",
    "+ setting the `datetime` column as the `Index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fe2c6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'eo:cloud_cover':'cloud_cover'})\n",
    "df.cloud_cover = df.cloud_cover.astype(np.float16)\n",
    "df = df.drop(['start_datetime', 'end_datetime'], axis=1)\n",
    "df = df.convert_dtypes()\n",
    "df.datetime = pd.DatetimeIndex(df.datetime)\n",
    "df = df.set_index('datetime').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb7cac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e122f38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The next step is to identify a smaller set of rows from the search results that we can work with more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba19a2f",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8bfc56",
   "metadata": {},
   "source": [
    "## Exploring & refining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b4e7d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The `VEG-DIST-STATUS` band of the DIST-ALERT data is what we want, so we need to extract only those rows from `df` that are associated with that particular band. To do so, we can construct a boolean series `c1` that is `True` whenever the string in the `asset` column includes `VEG-DIST-STATUS` as a sub-string. We can also construct a boolean series `c2` to filter out rows for which the `cloud_cover` exceeds 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e321fdd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c1 = df.asset.str.contains('VEG-DIST-STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e9828",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c2 = df.cloud_cover<20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7029978",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "If we examine the `tile_id` column, we can see that a single MGRS tile contains the AOI we specified. As such, all the data indexed in `df` corresponds to distinct measurements taken from a fixed geographic tile at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ebc4a8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.tile_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef50ff2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can combine the information above to reduce the `DataFrame` to a much shorter sequence of rows. We can also drop the `asset` and `tile_id` columns because they will be the same in every row after filtering. We can also drop the `cloud_cover` as we really only need the `href` column going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28458aaa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[c1 & c2].drop(['asset', 'tile_id', 'cloud_cover'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ea4a14",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcba2ed",
   "metadata": {},
   "source": [
    "## Data-wrangling to produce relevant output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79e224f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can examine the resulting `DataFrame` to see what information remains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b6e71",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634acebe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "There are almost eighty rows, each of which is associated with a distinct granule (in this context, a GeoTIFF file produced from an observation made at a given timestamp). We'll use a loop to assemble a stacked `DataArray` from the remote files using `xarray.concat`. Given that a few dozen files need to be retrieved from a remote source, this can take a few minutes and the result will require some memory (about 12 MiB for each row since each GeoTIFF corresponds to a $3,660\\times3,660$ array of 8-bit unsigned integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39954d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stack = stack_time_slices(df)\n",
    "stack.attrs = dict(description=f\"OPERA DIST: VEG-DIST-STATUS\", units=None)\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2a4c59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "As a reminder, for the `VEG-DIST-STATUS` band, we interpret the raster values as follows:\n",
    "\n",
    "* **0:** No disturbance\n",
    "* **1:** First detection of disturbance with vegetation cover change <50%\n",
    "* **2:** Provisional detection of disturbance with vegetation cover change <50%\n",
    "* **3:** Confirmed detection of disturbance with vegetation cover change <50%\n",
    "* **4:** First detection of disturbance with vegetation cover change ≥50%\n",
    "* **5:** Provisional detection of disturbance with vegetation cover change ≥50%\n",
    "* **6:** Confirmed detection of disturbance with vegetation cover change ≥50%\n",
    "* **7:** Finished detection of disturbance with vegetation cover change <50%\n",
    "* **8:** Finished detection of disturbance with vegetation cover change ≥50%\n",
    "* **255** Missing data\n",
    "\n",
    "By applying `np.unique` to the stack of rasters, we see that all these 10 distinct values occur somewhere in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa6aa6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1134cc6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll treat the pixels with missing values (i.e., value `255`) the same as pixels with no disturbance (i.e., value `0`). We could reassign the value `nan` to those pixels, but that converts all the data to `float32` or `float64` and hence increases the amount of memory required. That is, reassigning `255->0` allows us to ignore the missing values without using more memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36d3627",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stack = stack.where(stack!=255, other=0)\n",
    "\n",
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4e82d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll define a colormap to identify pixels showing signs of disturbance. Rather than assigning different colors to each of the 8 disturbance categories, we'll use [RGBA](https://en.wikipedia.org/wiki/RGBA_color_model) values to assign colors with a transparency value. With the colormap defined in the next cell, most of the pixels will be fully transparent. The remaining pixels are red with strictly positive `alpha` values. The values we really want to see are `3`, `6`, `7`, & `8` (indicating confirmed ongoing disturbance or confirmed disturbance that has finished)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f05d6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a colormap using RGBA values; these need to be written manually here...\n",
    "COLORS = [\n",
    "            (255, 255, 255, 0.0),   # No disturbance\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, first detection\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, provisional\n",
    "            (255,   0,   0, 0.50),  # <50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, first detection\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, provisional\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.75),  # <50% disturbance, finished\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, finished\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5770ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we're ready to produce visualizations using the array `stack`.\n",
    "\n",
    "+ We define `view` as a subset of `stack` that skips `steps` pixels in each direction to speed rendering (change to `steps=1` or `steps=None` when ready to plot at full resolution).\n",
    "+ We define dictionaries `image_opts` and `layout_opts` to control arguments to pass to `hvplot.image`.\n",
    "+ The result, when plotted, is an interactive plot with a slider that allows us to view specific time slices of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735d6e4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_opts = dict(\n",
    "                    x='longitude',\n",
    "                    y='latitude',\n",
    "                    cmap=COLORS,\n",
    "                    colorbar=False,\n",
    "                    clim=(-0.5,8.5),\n",
    "                    crs = stack.rio.crs,\n",
    "                    tiles=gv.tile_sources.ESRI,\n",
    "                    tiles_opts=dict(alpha=0.1, padding=0.1),\n",
    "                    project=True,\n",
    "                    rasterize=True,\n",
    "                    widget_location='bottom',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e29d7e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "layout_opts = dict(\n",
    "                    title = 'Great Green Wall, Sahel Region, Africa\\nDisturbance Alerts',\n",
    "                    xlabel='Longitude (°)',ylabel='Latitude (°)',\n",
    "                    fontscale=1.25,\n",
    "                    frame_width=500,\n",
    "                    frame_height=500,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160b722",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "steps = 100\n",
    "subset=slice(0,None,steps)\n",
    "view = stack.isel(longitude=subset, latitude=subset)\n",
    "view.hvplot.image(**image_opts, **layout_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2124eb6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "It can be difficult to see the red pixels with the entire region in view; the box zoom and wheel zoom tools are useful here. There is also some latency when using the slider as it takes some time to render a new slice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93512f0d",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
