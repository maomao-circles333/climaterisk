{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "193a446a",
   "metadata": {},
   "source": [
    "# Generating a Mosaicked Image of Lake Mead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7abe876",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "[Lake Mead](https://en.wikipedia.org/wiki/Lake_Mead) is a water reservoir in southwestern United States and is significant for irrigation in neighboring states. The lake has experienced significant drought over the past decade and particularly between 2020 & 2023. In this notebook, we'll find GeoTIFF data related to this lake and synthesize several raster files to produce a plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf9e9a",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a83cc",
   "metadata": {},
   "source": [
    "## Outline of steps for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5c813",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "+ Identifying search parameters\n",
    "    + AOI, time-window\n",
    "    + Endpoint, Provider, catalog identifier (\"short name\")\n",
    "+ Obtaining search results\n",
    "    + Instrospect, examine to identify features, bands of interest\n",
    "    + Wrap results into a DataFrame for easier exploration\n",
    "+ Exploring & refining search results\n",
    "    + Identify granules of highest value\n",
    "    + Filter extraneous granules with minimal contribution\n",
    "    + Assemble relevant filtered granules into DataFrame\n",
    "    + Identify kind of output to generate\n",
    "+ Data-wrangling to produce relevant output\n",
    "    + Download relevant granules into Xarray DataArray, stacked appropriately\n",
    "    + Do intermediate computations as necessary\n",
    "    + Assemble relevant data slices into visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02303c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368324f0",
   "metadata": {},
   "source": [
    "### Preliminary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096e497c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e844ce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports for plotting\n",
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "gv.extension('bokeh')\n",
    "from bokeh.models import FixedTicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22a5c2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# STAC imports to retrieve cloud data\n",
    "from pystac_client import Client\n",
    "from osgeo import gdal\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b78422",
   "metadata": {},
   "source": [
    "### Convenient utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5697f60b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "These functions could be placed in module files for more developed research projects. For learning purposes, they are embedded within this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc84f8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to make a rectangle with given center of width dx & height dy\n",
    "def make_bbox(pt,dx,dy):\n",
    "    '''Returns bounding-box represented as tuple (x_lo, y_lo, x_hi, y_hi)\n",
    "    given inputs pt=(x, y), width & height dx & dy respectively,\n",
    "    where x_lo = x-dx/2, x_hi=x+dx/2, y_lo = y-dy/2, y_hi = y+dy/2.\n",
    "    '''\n",
    "    return tuple(coord+sgn*delta for sgn in (-1,+1) for coord,delta in zip(pt, (dx/2,dy/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee724fe6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to plot an AOI or bounding-box\n",
    "def plot_bbox(bbox):\n",
    "    '''Given bounding-box, returns GeoViews plot of Rectangle & Point at center\n",
    "    + bbox: bounding-box specified as (lon_min, lat_min, lon_max, lat_max)\n",
    "    Assume longitude-latitude coordinates.\n",
    "    '''\n",
    "    # These plot options are fixed but can be over-ridden\n",
    "    point_opts = opts.Points(size=12, alpha=0.25, color='blue')\n",
    "    rect_opts = opts.Rectangles(line_width=0, alpha=0.1, color='red')\n",
    "    lon_lat = (0.5*sum(bbox[::2]), 0.5*sum(bbox[1::2]))\n",
    "    return (gv.Points([lon_lat]) * gv.Rectangles([bbox])).opts(point_opts, rect_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b19f64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to extract search results into a Pandas DataFrame\n",
    "def search_to_dataframe(search_results):\n",
    "    '''Constructs Pandas DataFrame from PySTAC Earthdata search results.\n",
    "    DataFrame columns are determined from search item properties and assets.'''\n",
    "    # Extract granules into a list of searh items\n",
    "    granules = list(search_results.items())\n",
    "    assert granules, \"Error: empty list of search results\"\n",
    "    # Determine column labels from unique properties from all granules\n",
    "    properties = sorted(list({prop for g in granules for prop in g.properties.keys()}))\n",
    "    # Assemble blocks of rows from each granule\n",
    "    blocks = []\n",
    "    for g in granules:\n",
    "        # Leftmost columns determined from properties\n",
    "        left = pd.Series(index=properties)\n",
    "        for p in properties:\n",
    "            left.loc[p] = g.properties.get(p, None)\n",
    "        tile_id = g.id.split('_')[3]\n",
    "        left.loc['tile_id'] = tile_id\n",
    "        left = pd.DataFrame(left).T\n",
    "        right = []\n",
    "        for a in sorted(g.assets.keys()):\n",
    "            href = g.assets[a].href\n",
    "            # Ignore hrefs using Amazon s3 (not currently working with rasterio)\n",
    "            if href.startswith('s3://'):\n",
    "                continue\n",
    "            right.append(pd.DataFrame(data=dict(asset=a, href=href), index=[0]))\n",
    "        # Use outer join to create block from left row and right block\n",
    "        blocks.append(left.join(pd.concat(right, axis=0, ignore_index=True), how='outer'))\n",
    "    # Stack blocks into final dataframe, forward-filling as needed\n",
    "    df = pd.concat(blocks, axis=0, ignore_index=True).ffill(axis=0)\n",
    "    assert len(df), \"Empty DataFrame\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427b689c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to remap pixel values to a sequence of contiguous integers\n",
    "def relabel_pixels(data, values, null_val=255, transparent_val=0, replace_null=True, start=0):\n",
    "    \"\"\"\n",
    "    This function accepts a DataArray with a finite number of categorical values as entries.\n",
    "    It reassigns the pixel labels to a sequence of consecutive integers starting from start.\n",
    "    data:            Xarray DataArray with finitely many categories in its array of values.\n",
    "    null_val:        (default 255) Pixel value used to flag missing data and/or exceptions.\n",
    "    transparent_val: (default 0) Pixel value that will be fully transparent when rendered.\n",
    "    replace_null:    (default True) Maps null_value->transparent_value everywhere in data.\n",
    "    start:           (default 0) starting range of consecutive integer values for new labels.\n",
    "    The values returned are:\n",
    "    new_data:        Xarray DataArray containing pixels with new values\n",
    "    relabel:         dictionary associating old pixel values with new pixel values\n",
    "    \"\"\"\n",
    "    new_data = data.copy(deep=True)\n",
    "    if values:\n",
    "        values = np.sort(np.array(values, dtype=np.uint8))\n",
    "    else:\n",
    "        values = np.sort(np.unique(data.values.flatten()))\n",
    "    if replace_null:\n",
    "        new_data = new_data.where(new_data!=null_val, other=transparent_val)\n",
    "        values = values[np.where(values!=null_val)]\n",
    "    n_values = len(values)\n",
    "    new_values = np.arange(start=start, stop=start+n_values, dtype=values.dtype)\n",
    "    assert transparent_val in new_values, f\"{transparent_val=} not in {new_values}\"\n",
    "    relabel = dict(zip(values, new_values))\n",
    "    for old, new in relabel.items():\n",
    "        if new==old: continue\n",
    "        new_data = new_data.where(new_data!=old, other=new)\n",
    "    return new_data, relabel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81d61c7",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286d8453",
   "metadata": {},
   "source": [
    "## Identifying search parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060cbec8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll identify a geographic point near the north shore of [Lake Mead](https://en.wikipedia.org/wiki/Lake_Mead), make a bounding box, and choose a date range that covers Marh and part of April 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c98ffbd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lake_mead = (-114.754, 36.131)\n",
    "AOI = make_bbox(lake_mead, 0.1, 0.1)\n",
    "DATE_RANGE = \"2023-03-01/2023-04-15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec5211",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Optionally plot the AOI\n",
    "basemap = gv.tile_sources.OSM(width=500, height=500, padding=0.1)\n",
    "plot_bbox(AOI) * basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477bc15f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "search_params = dict(bbox=AOI, datetime=DATE_RANGE)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71340719",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d06ade",
   "metadata": {},
   "source": [
    "## Obtaining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe1084",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "As usual, we'll specify the search endpoint, provider, & catalog. For the DSWx family of data products these are as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b9540",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "PROVIDER = 'POCLOUD'\n",
    "COLLECTIONS = [\"OPERA_L3_DSWX-HLS_V1_1.0\"]\n",
    "# Update the dictionary opts with list of collections to search\n",
    "search_params.update(collections=COLLECTIONS)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044cad1e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "catalog = Client.open(f'{ENDPOINT}/{PROVIDER}/')\n",
    "search_results = catalog.search(**search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb4e95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We convert the search results to a `DataFrame` for easier perusal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02e4785",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = search_to_dataframe(search_results)\n",
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09ec583",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll clean the DataFrame `df` in standard ways by:\n",
    "\n",
    "+ dropping the `start_datetime` & `end_datetime` columns;\n",
    "+ renaming the `eo:cloud_cover` column;\n",
    "+ converting the columns to suitable datatypes; and\n",
    "+ assigning the `datetime` column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66818b39",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.datetime = pd.DatetimeIndex(df.datetime)\n",
    "df = df.drop(['start_datetime', 'end_datetime'], axis=1)\n",
    "df = df.rename({'eo:cloud_cover':'cloud_cover'}, axis=1)\n",
    "df['cloud_cover'] = df['cloud_cover'].astype(np.float16)\n",
    "for col in ['asset', 'href', 'tile_id']:\n",
    "    df[col] = df[col].astype(pd.StringDtype())\n",
    "df = df.set_index('datetime').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a2d379",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "display(df.head())\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14a8bf",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e4aeb9",
   "metadata": {},
   "source": [
    "## Exploring & refining search results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7519f731",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can look at the `assets` column to see which different bands are available in the results returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3795833c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.asset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8d981e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The `0_B01_WTR` band is the one that we want to work with later.\n",
    "\n",
    "We can also see how much cloud cover there is in our search results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b0c919",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.cloud_cover.agg(['min','mean','median','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173f488",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We can extract selected rows from the `DataFrame` using boolean `Series`. Specifically, we'll select the rows that have less than 10% cloud cover and in which the `asset` is the `0_B01_WTR` band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac28ba3b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c1 = (df.cloud_cover <= 10)\n",
    "c2 = (df.asset.str.contains('B01_WTR'))\n",
    "b01_wtr = df.loc[c1 & c2].drop(['asset', 'cloud_cover'], axis=1)\n",
    "b01_wtr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeb7cee",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we can see how many different MGRS tiles intersect our AOI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a135be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "b01_wtr.tile_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dee7dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "There are four distinct geographic tiles that intersect this particular AOI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d38c3ca",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d1b980",
   "metadata": {},
   "source": [
    "## Data-wrangling to produce relevant output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b77af6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "This time, we'll use a technique called *mosaicking* to combine raster data from adjacent tiles into a single raster data set. This requires the `rasterio.merge.merge` function as before. We'll also need the function `rasterio.transform.array_bounds` to get the coordinates aligned properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdb39bf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.transform import array_bounds "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0fb0a7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We've used the function `merge` before to combine distinct raster data sets associated with a single MGRS tile. This time, the raster data merged will come from adjacent MGRS tiles. In calling the `merge` function in the next code cell, the column `b01_wtr.href` will be treated as a list of URLs ([Uniform Resource Locators](https://en.wikipedia.org/wiki/Uniform_Resource_Locator)). For each URL in that list, a GeoTIFF file will be downloaded and processed. The net result is a mosaicked image, i.e., a merged raster that contains a combination of all the rasters. The specifics of the merging algorithm are described in the [`rasterio.merge` module documentation](https://rasterio.readthedocs.io/en/latest/api/rasterio.merge.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6777e06",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mosaicked_img, mosaic_transform = merge(b01_wtr.href) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c5dee3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The output again consists of a NumPy array and coordinate transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e545b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{type(mosaicked_img)=}\\n\")\n",
    "print(f\"{mosaicked_img.shape=}\\n\")\n",
    "print(f\"{type(mosaic_transform)=}\\n\")\n",
    "print(f\"{mosaic_transform=}\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92eca11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "The entries of `mosaic_transform` describe an [*affine transformation*](https://en.wikipedia.org/wiki/Affine_transformation) from pixel coordinates to continuous UTM coordinates. In particular:\n",
    "\n",
    "+ the entry `mosaic_transform[0]` is the horizontal width of each pixel in metres; and\n",
    "+ the entry `mosaic_transform[4]` is the vertical height of each pixel in metres.\n",
    "  \n",
    "Notice also that, in this instance, `mosaic_transform[4]` is a negative value (i.e., `mosaic_transform[4]==-30.0`). This tells us that the orientation of the continuous coordinate vertical axis opposes the orientation of the vertical pixel coordinate axis, i.e., the vertical continuous coordinate decreases in a downwards direction unlike the vertical pixel coordinate.\n",
    "\n",
    "When we pass the object `mosaic_transform` into the `rasterio.transform.array_bounds` function, the value returned is a bounding-box, i.e., a tuple of the form `(x_min, y_min, x_max, y_max)` describing the lower-left and upper-right corners of the resulting mosaicked image in continuous UTM coordinates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406258d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bounds = array_bounds(*mosaicked_img.shape[1:], mosaic_transform)\n",
    "\n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7594ac15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Combining all the preceding information allows us to reconstruct the continuous UTM coordinates associated with each pixel. We'll compute arrays for these continuous coordinates and label them `longitude` and `latitude`. These coordinates would more accurately be called `easting` and `northing`, but we'll use the labels `longitude` and `latitude` respectively when we attach the coordinate arrays to an Xarray `DataArray`. We choose these labels because, when the raster data is plotted with `hvplot.image`, the output will use longitude-latitude coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e98768a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "longitude = np.arange(bounds[0], bounds[2], mosaic_transform[0])\n",
    "latitude = np.arange(bounds[3], bounds[1], mosaic_transform[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148995c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll wrap the mosaicked image and the relevant metadata into an Xarray `DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f659a5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raster = xr.DataArray(\n",
    "        data=mosaicked_img,\n",
    "        dims=[\"band\", \"latitude\", \"longitude\"],\n",
    "        coords=dict(\n",
    "            longitude=([\"longitude\"], longitude),\n",
    "            latitude=([\"latitude\"], latitude),\n",
    "        ),\n",
    "        attrs=dict(\n",
    "            description=\"OPERA DSWx B01\",\n",
    "            units=None,\n",
    "        ),\n",
    "    )\n",
    "raster "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9431cb1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We need to attach a CRS object to the `raster` object. To do so, we'll use `rasterio.open` to load the relevant metadata from one of the granules associated with `b01_wtr` (these should be the same for all these particular files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df498d19",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with rasterio.open(b01_wtr.href[0]) as ds:\n",
    "    crs = ds.crs\n",
    "\n",
    "raster.rio.write_crs(crs, inplace=True)\n",
    "print(raster.rio.crs) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b00c2b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "In research code, we could bundle the preceding commands within a function and save that to a module. We won't do that here because, for the purposes of this tutorial, it's preferable to make sure that we can examine the output of various lines of code interactively.\n",
    "\n",
    "With all the preceding steps completed, we're ready to produce a plot of the mosaicked raster. We'll relabel the pixel values so that the colorboar in the final result will be tidier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1160f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raster, relabel = relabel_pixels(raster, values=[0,1,2,253,254,255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea59f4f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll define image options, layout options, & a colormap in dictionaries as we've done previously to produce a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8fd5da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_opts = dict(\n",
    "                    x='longitude',\n",
    "                    y='latitude',                   \n",
    "                    rasterize=True, \n",
    "                    dynamic=True,\n",
    "                    crs=raster.rio.crs\n",
    "                 )\n",
    "layout_opts = dict(\n",
    "                    xlabel='Longitude',\n",
    "                    ylabel='Latitude',\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10a844f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a colormap using RGBA values; these need to be written manually here...\n",
    "COLORS = {\n",
    "0: (255, 255, 255, 0.0),  # No Water\n",
    "1:  (0,   0, 255, 1.0),   # Open Water\n",
    "2:  (180, 213, 244, 1.0), # Partial Surface Water\n",
    "3: (  0, 255, 255, 1.0),  # Snow/Ice\n",
    "4: (175, 175, 175, 1.0),  # Cloud/Cloud Shadow\n",
    "5: ( 0,   0, 127, 0.5),   # Ocean Masked\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36747e5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c_labels = [\"Not water\", \"Open water\", \"Partial Surface Water\", \"Snow/Ice\",\n",
    "            \"Cloud/Cloud Shadow\", \"Ocean Masked\"]\n",
    "c_ticks = list(COLORS.keys())\n",
    "limits = (c_ticks[0]-0.5, c_ticks[-1]+0.5)\n",
    "\n",
    "c_bar_opts = dict( ticker=FixedTicker(ticks=c_ticks),\n",
    "                   major_label_overrides=dict(zip(c_ticks, c_labels)),\n",
    "                   major_tick_line_width=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2a271",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_opts.update({ 'cmap': list(COLORS.values()),\n",
    "                    'clim': limits,\n",
    "                  })\n",
    "\n",
    "layout_opts.update(dict(colorbar_opts=c_bar_opts)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f3327",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "We'll define the basemap as a separate object to overlay using the `*` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94992bcf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "basemap = gv.tile_sources.ESRI(frame_width=500, frame_height=500, padding=0.05, alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c3f8c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Finally, we can use the builtin Python `slice` function to extract downsampled images quickly before trying to view the entire image. Remember, reducing the value `steps` to `1` (or `None`) plots the raster at full resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4f5105",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "steps = 1\n",
    "view = raster.isel(longitude=slice(0,None,steps), latitude=slice(0,None,steps)).squeeze()\n",
    "\n",
    "view.hvplot.image(**image_opts).opts(**layout_opts) * basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726ee23",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "This raster is much larger than ones we've previously examined (requiring roughly 4 times the storage). This process could be iterated to make a slider showing the merged results from neighboring tiles at different times. This, of course, requires that there is enough memory available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0042d4",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
