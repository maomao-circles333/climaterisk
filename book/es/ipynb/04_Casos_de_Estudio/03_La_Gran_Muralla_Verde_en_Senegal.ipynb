{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1dc0a17",
   "metadata": {},
   "source": [
    "# La Gran Muralla Verde en Senegal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90972844",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "[La Gran Muralla Verde](https://es.wikipedia.org/wiki/Gran_muralla_verde_\\(%C3%81frica\\)) es un esfuerzo para combatir la expansión del desierto del Sahara mediante el crecimiento de vegetación de forma sistemática y científica. El [producto OPERA DIST-ALERT](https://lpdaac.usgs.gov/documents/1766/OPERA_DIST_HLS_Product_Specification_V1.pdf) también puede utilizarse para identificar cambios en el crecimiento de la vegetación (que impliquen causas naturales o, en este caso, antropogénicas).\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Sahara_satellite_hires.jpg/800px-Sahara_satellite_hires.jpg\">\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56852f",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad08232",
   "metadata": {},
   "source": [
    "## Esquema de las etapas del análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cc2a3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "- Identificación de los parámetros de búsqueda (AOI, ventana de tiempo, _endpoint_, etc.)\n",
    "- Obtención de los resultados de la búsqueda en un `DataFrame`\n",
    "- Exploración y refinamiento de los resultados de la búsqueda\n",
    "- Procesamiento de los datos para obtener resultados relevantes\n",
    "\n",
    "En este caso, crearemos un DataFrame para resumir los resultados de la búsqueda, los reduciremos a un tamaño manejable y crearemos un control deslizante para analizar los datos recuperados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d33e62",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3c382b",
   "metadata": {},
   "source": [
    "### Importación preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d7dfb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import numpy as np, pandas as pd, xarray as xr\n",
    "import rioxarray as rio\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6723020",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import hvplot.pandas, hvplot.xarray\n",
    "import geoviews as gv\n",
    "from geoviews import opts\n",
    "gv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb01774",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from pystac_client import Client\n",
    "from osgeo import gdal\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/.cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e663329",
   "metadata": {},
   "source": [
    "### Funciones de utilidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc0837",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to make a rectangle with given center of width dx & height dy\n",
    "def make_bbox(pt,dx,dy):\n",
    "    '''Returns bounding-box represented as tuple (x_lo, y_lo, x_hi, y_hi)\n",
    "    given inputs pt=(x, y), width & height dx & dy respectively,\n",
    "    where x_lo = x-dx/2, x_hi=x+dx/2, y_lo = y-dy/2, y_hi = y+dy/2.\n",
    "    '''\n",
    "    return tuple(coord+sgn*delta for sgn in (-1,+1) for coord,delta in zip(pt, (dx/2,dy/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b06aa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# simple utility to plot an AOI or bounding-box\n",
    "def plot_bbox(bbox):\n",
    "    '''Given bounding-box, returns GeoViews plot of Rectangle & Point at center\n",
    "    + bbox: bounding-box specified as (lon_min, lat_min, lon_max, lat_max)\n",
    "    Assume longitude-latitude coordinates.\n",
    "    '''\n",
    "    # These plot options are fixed but can be over-ridden\n",
    "    point_opts = opts.Points(size=12, alpha=0.25, color='blue')\n",
    "    rect_opts = opts.Rectangles(line_width=0, alpha=0.1, color='red')\n",
    "    lon_lat = (0.5*sum(bbox[::2]), 0.5*sum(bbox[1::2]))\n",
    "    return (gv.Points([lon_lat]) * gv.Rectangles([bbox])).opts(point_opts, rect_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8ee0b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to extract search results into a Pandas DataFrame\n",
    "def search_to_dataframe(search_results):\n",
    "    '''Constructs Pandas DataFrame from PySTAC Earthdata search results.\n",
    "    DataFrame columns are determined from search item properties and assets.'''\n",
    "    # Extract granules into a list of searh items\n",
    "    granules = list(search_results.items())\n",
    "    assert granules, \"Error: empty list of search results\"\n",
    "    # Determine column labels from unique properties from all granules\n",
    "    properties = sorted(list({prop for g in granules for prop in g.properties.keys()}))\n",
    "    # Assemble blocks of rows from each granule\n",
    "    blocks = []\n",
    "    for g in granules:\n",
    "        # Leftmost columns determined from properties\n",
    "        left = pd.Series(index=properties)\n",
    "        for p in properties:\n",
    "            left.loc[p] = g.properties.get(p, None)\n",
    "        tile_id = g.id.split('_')[3]\n",
    "        left.loc['tile_id'] = tile_id\n",
    "        left = pd.DataFrame(left).T\n",
    "        right = []\n",
    "        for a in sorted(g.assets.keys()):\n",
    "            href = g.assets[a].href\n",
    "            # Ignore hrefs using Amazon s3 (not currently working with rasterio)\n",
    "            if href.startswith('s3://'):\n",
    "                continue\n",
    "            right.append(pd.DataFrame(data=dict(asset=a, href=href), index=[0]))\n",
    "        # Use outer join to create block from left row and right block\n",
    "        blocks.append(left.join(pd.concat(right, axis=0, ignore_index=True), how='outer'))\n",
    "    # Stack blocks into final dataframe, forward-filling as needed\n",
    "    df = pd.concat(blocks, axis=0, ignore_index=True).ffill(axis=0)\n",
    "    assert len(df), \"Empty DataFrame\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2010e16c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# utility to process DataFrame of search results & return DataArray of stacked raster images\n",
    "def stack_time_slices(granule_dataframe):\n",
    "    '''This function returns a three-dimensional Xarray DataArray comprising time slices read from GeoTIFF files.\n",
    "    - Input: a DataFrame of granules (i.e., a DataFrame with a DateTimeIndex and a column 'href' of URIs).\n",
    "    - Output: a stacked DataArray with dimensions ('time', 'longitude', 'latitude')\n",
    "    - GeoTIFF data are assumed to have been acquired over the same MGRS tile (NOT verified within).\n",
    "    - Note CRS explicitly embedded into DataArray stack as extracted from GeoTIFF file.\n",
    "    - DataArray is constructed using np.datetime64 time axis to simplify visualization.'''\n",
    "    slices, timestamps = list(), list()\n",
    "    for timestamp_, row_ in granule_dataframe.iterrows():\n",
    "        da_ = rio.open_rasterio(row_['href'])\n",
    "        # Preserve coordinate arrays from last GeoTIFF file parsed\n",
    "        x, y = da_.coords['x'].values, da_.coords['y'].values\n",
    "        slices.append(da_.values)\n",
    "        timestamps.append(np.datetime64(timestamp_,'s'))\n",
    "    # Construct time axis from accumulated timestamps\n",
    "    time = np.array(timestamps)\n",
    "    # Construct DataArray stack from accumulated slices & coordinates\n",
    "    slices = np.concatenate(slices, axis=0)\n",
    "    coords = dict(time=time, longitude=x, latitude=y)\n",
    "    stack = xr.DataArray(data=slices, coords=coords, dims=['time', 'latitude', 'longitude'])\n",
    "    # Preserve coordinate reference system (CRS) in DataArray stack\n",
    "    crs = da_.rio.crs\n",
    "    stack.rio.write_crs(crs, inplace=True)\n",
    "    return stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a5831",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Estas funciones podrían incluirse en archivos modulares para proyectos de investigación más desarrollados. Para fines didácticos, se incluyen en este cuaderno computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fd96a4",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729759ca",
   "metadata": {},
   "source": [
    "## Obtención de los resultados de búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463de655",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "La Gran Muralla Verde se extiende por el continente africano. Elegiremos un área de interés centrada en las coordenadas geográficas $(-16.0913^{\\circ}, 16.528^{\\circ})$ en Senegal. Analizaremos todos los datos disponibles desde enero de 2022 hasta finales de marzo de 2024. Usaremos los identificadores `AOI` y `DATE_RANGE` para utilizarlos eventualmente en una consulta de búsqueda PySTAC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687148e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "AOI = make_bbox((-16.0913, 16.528), 0.1, 0.1)\n",
    "DATE_RANGE = \"2022-01-01/2024-03-31\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565e5fd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "El gráfico que se genera a continuación ilustra el AOI. Las herramientas Bokeh Zoom son útiles para analizar la caja en varias escalas de longitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8671bed4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Optionally plot the AOI\n",
    "basemap = gv.tile_sources.OSM(padding=0.1, alpha=0.25)\n",
    "plot_bbox(AOI) * basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e59174",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "search_params = dict(bbox=AOI, datetime=DATE_RANGE)\n",
    "print(search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a68f97a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Para ejecutar la búsqueda, definimos la URI del punto final e instanciamos el objeto `Client`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75323d29",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ENDPOINT = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "PROVIDER = 'LPCLOUD'\n",
    "COLLECTIONS = [\"OPERA_L3_DIST-ALERT-HLS_V1_1\"]\n",
    "search_params.update(collections=COLLECTIONS)\n",
    "print(search_params)\n",
    "\n",
    "catalog = Client.open(f'{ENDPOINT}/{PROVIDER}/')\n",
    "search_results = catalog.search(**search_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d0b3ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "La búsqueda en sí es bastante rápida y arroja algunos miles de resultados que pueden analizarse más fácilmente en un  DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7710798",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = search_to_dataframe(search_results)\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6bf6da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Limpiaremos el `DataFrame` `df` como lo venimos haciendo de manera habitual:\n",
    "\n",
    "- renombramos la columna `eo:cloud_cover` como `cloud_cover`,\n",
    "- eliminamos las columnas `datetime` extrañas,\n",
    "- convertimos las columnas en tipos de datos sensibles,\n",
    "- convertimos la columna `datetime` en `DatetimeIndex`, y\n",
    "- establecemos la columna `datetime` como `Index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8006d0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.rename(columns={'eo:cloud_cover':'cloud_cover'})\n",
    "df.cloud_cover = df.cloud_cover.astype(np.float16)\n",
    "df = df.drop(['start_datetime', 'end_datetime'], axis=1)\n",
    "df = df.convert_dtypes()\n",
    "df.datetime = pd.DatetimeIndex(df.datetime)\n",
    "df = df.set_index('datetime').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4570dc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409af610",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "El siguiente paso es identificar un conjunto con una cantidad menor de filas a partir de los resultados de la búsqueda con los que podamos trabajar más fácilmente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff68898",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd353e32",
   "metadata": {},
   "source": [
    "## Exploración y refinamiento de los resultados de la búsqueda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92531d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Lo que queremos es la banda `VEG-DIST-STATUS` de los datos DIST-ALERT, así que debemos extraer solamente las filas del `df` asociadas a esa banda. Para ello, podemos construir una serie booleana `c1` que sea `True` siempre que la cadena de la columna `asset` incluya `VEG-DIST-STATUS` como subcadena. También podemos construir una serie booleana `c2` para filtrar las filas cuya `cloud_cover` exceda el 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19abd35",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c1 = df.asset.str.contains('VEG-DIST-STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e28b3d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c2 = df.cloud_cover<20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e81a6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Si analizamos la columna `tile_id`, podemos ver que un único mosaico MGRS contiene el AOI que especificamos. Como tal, todos los datos indexados en `df` corresponden a mediciones distintas tomadas de un mosaico geográfico fijo en diferentes momentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adf1555",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df.tile_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6307c095",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Podemos combinar la información anterior para reducir el `DataFrame` a una secuencia de filas mucho más pequeña. También podemos eliminar las columnas `asset` y `tile_id` porque serán las mismas en todas las filas después del filtrado. También podemos eliminar la columna `cloud_cover`, ya que en lo sucesivo solo necesitaremos la columna `href`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facc83d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = df.loc[c1 & c2].drop(['asset', 'tile_id', 'cloud_cover'], axis=1)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f31f632",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef099286",
   "metadata": {},
   "source": [
    "## Procesamiento de los datos para obtener resultados relevantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b95f45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Podemos analizar el `DataFrame` para ver cuál es la información resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caad0f1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56931a11",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Hay casi ochenta filas, cada una de las cuales está asociada a un gránulo distinto (en este contexto, un archivo GeoTIFF producido a partir de una observación efectuada en una fecha y hora determinadas). Utilizaremos un bucle para crear un `DataArray` apilado a partir de los archivos remotos utilizando `xarray.concat`. Dado que se deben recuperar algunas docenas de archivos de una fuente remota, esto puede tardar unos minutos y el resultado requerirá algo de memoria (unos 12 MiB por cada fila, ya que cada GeoTIFF corresponde a una matriz de $3,660\\times3,660$ de enteros de 8 bits sin signo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555b78c4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stack = stack_time_slices(df)\n",
    "stack.attrs = dict(description=f\"OPERA DIST: VEG-DIST-STATUS\", units=None)\n",
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09469455",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "A modo de recordatorio, para la banda `VEG-DIST-STATUS`, interpretaremos los valores del ráster de la siguiente manera:\n",
    "\n",
    "- **0:** Sin alteración\n",
    "- **1:** Primera detección de alteraciones con cambios en la cobertura vegetal <50%\n",
    "- **2:** Detección provisional de alteraciones con cambios en la cobertura vegetal <50%\n",
    "- **3:** Detección confirmada de alteraciones con cambios en la cobertura vegetal < 50%\n",
    "- **4:** Primera detección de alteraciones con cambios en la cobertura vegetal ≥50%\n",
    "- **5:** Detección provisional de alteraciones con cambios en la cobertura vegetal ≥50%\n",
    "- **6:** Detección confirmada de alteraciones con cambios en la cobertura vegetal ≥50%\n",
    "- **7:** Detección finalizada de alteraciones con cambios en la cobertura vegetal <50%\n",
    "- **8:** Detección finalizada de alteraciones con cambios en la cobertura vegetal ≥50%\n",
    "- **255** Datos faltantes\n",
    "\n",
    "Al aplicar `np.unique` a la pila de rásters, vemos que estos 10 valores distintos aparecen en algún lugar de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b00809",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07c6f22",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Trataremos los píxeles con valores faltantes (por ejemplo, el `255`) igual que los píxeles sin alteraciones (por ejemplo, el valor `0`). Podríamos reasignar el valor `nan` a esos píxeles, pero eso convierte todos los datos a `float32` o `float64` y, por lo tanto, aumenta la cantidad de memoria requerida. Es decir, reasignar `255->0` nos permite ignorar los valores que faltan sin utilizar más memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ea1ef",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stack = stack.where(stack!=255, other=0)\n",
    "\n",
    "np.unique(stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d7bb96",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Definiremos un mapa de colores para identificar los píxeles que muestran signos de alteraciones. En vez de asignar colores diferentes a cada una de las 8 categorías de alteraciones, utilizaremos [valores RGBA](https://es.wikipedia.org/wiki/Espacio_de_color_RGBA) para asignar colores con un valor de transparencia. Con el mapa de colores definido en la siguiente celda, la mayoría de los píxeles serán totalmente transparentes. Los píxeles restantes son de color rojo con valores `alpha` estrictamente positivos. Los valores que realmente queremos ver son `3`, `6`, `7` y `8` (que indican una alteración confirmada en curso o una alteración confirmada que finalizó)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12baf4ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define a colormap using RGBA values; these need to be written manually here...\n",
    "COLORS = [\n",
    "            (255, 255, 255, 0.0),   # No disturbance\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, first detection\n",
    "            (255,   0,   0, 0.25),  # <50% disturbance, provisional\n",
    "            (255,   0,   0, 0.50),  # <50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, first detection\n",
    "            (255,   0,   0, 0.50),  # ≥50% disturbance, provisional\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, confirmed, ongoing\n",
    "            (255,   0,   0, 0.75),  # <50% disturbance, finished\n",
    "            (255,   0,   0, 1.00),  # ≥50% disturbance, finished\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9029773d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Ya podemos, entonces, producir visualizaciones utilizando la matriz `stack`.\n",
    "\n",
    "- Definimos `view` como un subconjunto de `stack` que se salta `steps` de píxeles en cada dirección para acelerar el renderizado (cambiar a `steps=1` o `steps=None` cuando querramos graficar a resolución completa).\n",
    "- Definimos los diccionarios `image_opts` y `layout_opts` para controlar los argumentos que pasaremos a `hvplot.image`.\n",
    "- El resultado, cuando se visualiza, es un gráfico interactivo con un selector que nos permite ver cortes temporales específicos de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3860246f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "image_opts = dict(\n",
    "                    x='longitude',\n",
    "                    y='latitude',\n",
    "                    cmap=COLORS,\n",
    "                    colorbar=False,\n",
    "                    clim=(-0.5,8.5),\n",
    "                    crs = stack.rio.crs,\n",
    "                    tiles=gv.tile_sources.ESRI,\n",
    "                    tiles_opts=dict(alpha=0.1, padding=0.1),\n",
    "                    project=True,\n",
    "                    rasterize=True,\n",
    "                    widget_location='bottom',\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca4f72",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "layout_opts = dict(\n",
    "                    title = 'Great Green Wall, Sahel Region, Africa\\nDisturbance Alerts',\n",
    "                    xlabel='Longitude (°)',ylabel='Latitude (°)',\n",
    "                    fontscale=1.25,\n",
    "                    frame_width=500,\n",
    "                    frame_height=500,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabfbfac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "steps = 100\n",
    "subset=slice(0,None,steps)\n",
    "view = stack.isel(longitude=subset, latitude=subset)\n",
    "view.hvplot.image(**image_opts, **layout_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c7e192",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "Puede ser difícil ver los píxeles de color rojo con toda la región a la vista. Las herramientas zoom de caja y zoom de rueda son útiles aquí. También hay cierta latencia cuando se utiliza el selector, ya que se tarda un tiempo en renderizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9f110c",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
